== ALB migration guide

Follow this guide to update the ALB modules (both public and internal)
to the Service Catalog.

=== Estimated Time to Migrate: 5-10 minutes per ALB

=== New Required Inputs

Configure these new inputs to migrate to the Service Catalog version of
the module. They are now required.

* `vpc_id`: The VPC ID where the ALB should be located. This should be
pulled in with a `dependency` block against the `vpc-app` service, using
the `vpc_id` output.
* `vpc_subnet_ids`: The IDs of the private app subnets where the ALB
should be located. This should be pulled in with a `dependency` block
against the `vpc-app` service, using the `public_subnet_ids` or
`private_app_subnet_ids` output (depending on if it is a public or
internal ALB).

=== Inputs for Backward Compatibility

Configure the following new inputs to ensure your service continues to
function with minimal interruption. These are necessary to maintain
backward compatibility. _If left unset, you will risk redeploying the
service and causing downtime._

* `custom_tags`: Review any tags on the existing ALB and security group
resource. Provide those tags in the `custom_tags` input map. For
example:

....
custom_tags = {
    Environment = "dev"
}
....

* `hosted_zone_id`: The ID of the private route53 hosted zone. This
should be sourced using a `dependency` block against the
`route53-private` or `route53-public` service, using the
`internal_services_hosted_zone_id` or `primary_domain_hosted_zone_id`
output (depending on if it is an internal or public ALB).
* `allow_inbound_from_security_group_ids`: A list of security group IDs
that should be allowed to access the internal ALB, such as the VPN
server, or a front end application. This should be sourced using a
`dependency` block also. In the past, this wast calculated in the
module, but now must be looked up with a `dependency`. Example:

....
allow_inbound_from_security_group_ids = [dependency.openvpn_server.outputs.security_group_id]
....

* `allow_inbound_from_cidr_blocks`: A list of CIDR blocks that should be
allowed to access the internal ALB, such as the CIDR range of the VPC,
or of a specific list of subnets. This should be sourced using a
`dependency` block also. In the past, this was calculated in the module,
but now must be looked up with a `dependency`. Example:

....
 allow_inbound_from_cidr_blocks = [dependency.vpc.outputs.vpc_cidr_block]
....

=== Renamed Inputs

Rename the following inputs to use the Service Catalog version of the
module:

* `domain_name` ⇒ `domain_names`. This variable now accepts a list of
strings rather than a scalar.

=== Removed Inputs

Remove the following inputs as they are not present in the Service
Catalog version of the module:

* `https_listener_ports_and_ssl_certs_num`
* `https_listener_ports_and_acm_ssl_certs_num`

=== Output Changes

Update downstream dependency references to use the new names of these
outputs, which were renamed in the Service Catalog version of the
module.

* `alb_dns_name` ⇒ `alb_dns_names`: Now a list of DNS names, including
the friendly route53 name and the autogenerated ALB DNS record.
* [NEW] `alb_access_logs_bucket`: The name of the ALB access logs
bucket.

=== State Migration Script

Run the provided migration script (contents pasted below for
convenience) to migrate the state in a backward compatible way:

[source,python]
----
#!/bin/bash
# This script contains the state migration instructions for migrating ALBs to the Service Catalog from the old
# style Gruntwork Reference Architecture. Install this script and run it from the terragrunt live configuration
# directory of the module to perform the state operations.
#

set -e
set -o pipefail

# Import the helper functions from the repo root.
readonly infra_live_repo_root="$(git rev-parse --show-toplevel)"
source "$infra_live_repo_root/_scripts/migration_helpers.sh"

function run {
  local domain_name=$(grep -E '^\s*domain_name\s*=\s*' terragrunt.hcl | grep -oE '".*"' | tr -d '"')
  if [[ "$domain_name" == "" ]]; then
    log "Unable to find domain in terragrunt.hcl. Skipping domain name migration."
  else
    # Move the dns record to the new map location
    fuzzy_move_state \
      'aws_route53_record.dns_record$' \
      "aws_route53_record.dns_record[\"$domain_name\"]" \
      'DNS record'
  fi

  # Move the access logs bucket and policy to the new state location
  fuzzy_move_state \
    'module.alb_access_logs_bucket.aws_s3_bucket.access_logs_with_logs_archived_and_deleted$' \
    'module.alb_access_logs_bucket.module.access_logs.aws_s3_bucket.bucket[0]'
    'ALB Access Logs bucket'
}

run "$@"
----

=== Breaking Changes

* When applying the change, the bucket policy will be removed from the
bucket resource and will be replaced with a new `aws_s3_bucket_policy`
resource. This policy allows ALB to deliver access logs to the S3
bucket. The existing bucket is NOT destroyed, but the policy is
recreated, which may cause a brief outage (<1 minute) in access log
delivery while the policy change occurs.
* The policy will now require the use of TLS when making requests to the
access logs bucket.
* Encryption will be enabled on the bucket. This cannot be disabled.
* Public access to the bucket will be blocked. This cannot be disabled.
* If you are using `https_listener_ports_and_acm_ssl_certs` to map ports
to ACM-issued TLS certificates, upon apply you will see a change to the
certificate ARN. It is now being looked up with a data source, and the
change is a no-op.
