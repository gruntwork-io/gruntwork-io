---
title: k8s-service Migration Guide
categories: Upgrades
image: /assets/img/guides/refresh_icon.png
excerpt: Learn how to update your v1 Reference Architecture to use the Gruntwork Service Catalog.
tags: ["aws", "terraform", "terragrunt"]
cloud: ["aws"]
redirect_from: /static/guides/upgrades/how-to-update-your-ref-arch/
---
:page-type: guide
:page-layout: post

:toc:
:toc-placement!:

// GitHub specific settings. See https://gist.github.com/dcode/0cfbf2699a1fe9b46ff04c41721dda74 for details.
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
toc::[]
endif::[]

== k8s-service Migration Guide

Follow this guide to update the k8s-service to the Service Catalog.

Cross-reference with the example changes shown in these patches:
* link:https://github.com/gruntwork-io/infrastructure-live-multi-account-acme/blob/master/dev/us-east-1/dev/services/k8s-sample-app-backend-multi-account-acme/ref-arch-v1-to-service-catalog-migration.patch[k8s-service (backend)]
* link:https://github.com/gruntwork-io/infrastructure-live-multi-account-acme/blob/master/dev/us-east-1/dev/services/k8s-sample-app-frontend-multi-account-acme/ref-arch-v1-to-service-catalog-migration.patch[k8s-service (frontend)]

=== Estimated Time to Migrate: 25 minutes per environment

=== New generate block

Add the following https://terragrunt.gruntwork.io/docs/reference/config-blocks-and-attributes/#generate[`generate`
block] to your `terragrunt.hcl`.

[source,python]
----
# Generate a Kubernetes provider configuration for authenticating against the EKS cluster.
generate "k8s_helm" {
  path      = "k8s_helm_provider.tf"
  if_exists = "overwrite_terragrunt"
  contents = templatefile(
    find_in_parent_folders("provider_k8s_helm_for_eks.template.hcl"),
    { eks_cluster_name = dependency.eks_cluster.outputs.eks_cluster_name },
  )
}
----

This block points to a file `provider_k8s_helm_for_eks.template.hcl`, which you’ll have to create at the root of the
repo. It should be a sibling of the `terragrunt_service_catalog.hcl` file you added as part of preparing the repo for
the migration.

Paste the following contents into the `provider_k8s_helm_for_eks.template.hcl` file:

[source,python]
----
data "aws_eks_cluster" "cluster_for_provider" {
  name = "${eks_cluster_name}"
}

provider "kubernetes" {
  load_config_file       = false
  host                   = data.aws_eks_cluster.cluster_for_provider.endpoint
  cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster_for_provider.certificate_authority.0.data)

  # EKS clusters use short-lived authentication tokens that can expire in the middle of an 'apply' or 'destroy'. To
  # avoid this issue, we use an exec-based plugin here to fetch an up-to-date token. Note that this code requires the
  # kubergrunt binary to be installed and on your PATH.
  exec {
    api_version = "client.authentication.k8s.io/v1alpha1"
    command     = "kubergrunt"
    args        = ["eks", "token", "--cluster-id", "${eks_cluster_name}"]
  }
}

provider "helm" {
  kubernetes {
    host                   = data.aws_eks_cluster.cluster_for_provider.endpoint
    cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster_for_provider.certificate_authority.0.data)

    # EKS clusters use short-lived authentication tokens that can expire in the middle of an 'apply' or 'destroy'. To
    # avoid this issue, we use an exec-based plugin here to fetch an up-to-date token. Note that this code requires the
    # kubergrunt binary to be installed and on your PATH.
    exec {
      api_version = "client.authentication.k8s.io/v1alpha1"
      command     = "kubergrunt"
      args        = ["eks", "token", "--cluster-id", "${eks_cluster_name}"]
    }
  }
}
----

=== New Required Input

Configure the new `container_image` input, which is a map of three keys:

* `repository`: Set this to the `image` input in the old version.
* `tag`: Set this to the `image_version` input in the old version.
* `pull_policy`: Possible values are `IfNotPresent`, `Always`, and `Never`. Set to `IfNotPresent`.

For example:

[source,python]
----
container_image = {
  repository  = <IMAGE>
  tag         = <IMAGE_VERSION>
  pull_policy = "IfNotPresent"
}
----

=== Inputs for Backward Compatibility

Configure the following new inputs to ensure your service continues to function with minimal interruption. These are
necessary to maintain backward compatibility. _If left unset, you will risk redeploying the service and causing
downtime._

* Set a new locals block that pulls the region information:
+
[source,python]
----
locals {
  region_vars = yamldecode(file(find_in_parent_folders("region.yaml")))
}
----
* `env_vars`: This is now a map of environment variables. Configure all the environment variables necessary for your
app. Use terragrunt https://terragrunt.gruntwork.io/docs/reference/config-blocks-and-attributes/#dependency[`dependency`
blocks] to pull dynamic information, like the database URL and cache URL. The following is an example of configuring the
environment variables for the Gruntwork sample app in backend mode:
+
[source,python]
----
dependency "database" {
  config_path = "../../data-stores/postgres"
}

dependency "cache" {
  config_path = "../../data-stores/memcached"
}

inputs = {
  env_vars = {
    VPC_NAME      = "dev"
      AWS_REGION    = local.region_vars.aws_region

      # NOTE: this dependency should point to the database service config.
      DB_URL        = dependency.database.outputs.primary_host

      # NOTE: this dependency should point to the cache service config.
      MEMCACHED_URL = dependency.cache.outputs.cache_addresses[0]

      BACKEND_URL   = "sample-app-backend.applications.svc.cluster.local"
      BACKEND_PORT  = 443
  }
}
----
* IAM Roles for Service Accounts
** The new Service Catalog based Reference Architecture limits access to the AWS API from EKS for better security. For
backward compatibility, you need to configure your `k8s-service` to access the KMS master key to decrypt secrets used
for database access. You also need to do this to avoid downtime with the application unable to access the database.
** `service_account_name`: Choose a name that describes the service, e.g. ``eks-application''.
** `iam_role_name`: Choose a name that describes the `k8s-service`, typically whatever you use for
`service_account_name`.
** `eks_iam_role_for_service_accounts_config`: For now, hard-code the values for the OpenID Connect provider ARN and URL
by running this command: `aws iam list-open-id-connect-providers | jq -r '.OpenIDConnectProviderList[].Arn` The last
part of the ARN is the URL: `arn:aws:iam::<ACCOUNT_ID>:oidc-provider/<OpenID_Connect_Provider_URL>` For now, you will
have something like:
`eks_iam_role_for_service_accounts_config = {       openid_connect_provider_arn = "arn:aws:iam::<ACCOUNT_ID>:oidc-provider/oidc.eks.<REGION>.amazonaws.com/id/<HASH>"       openid_connect_provider_url = "oidc.eks.<REGION>.amazonaws.com/id/<HASH>"     }`
You can update this input from a hard-coded map to the `eks_iam_role_for_service_accounts_config` output of the
`eks_cluster` dependency only _after migrating the `eks-cluster` service_.
** `iam_role_exists`: You are creating a new IAM role, so set this to `false`.
** `iam_policy`: Set this to the IAM policy permissions necessary to operate your application. For example, the sample
apps need access to the KMS key for `gruntkms`, so the `iam_policy` uses the `key_arn` output of the `kms-master-key`
module like so:
`dependency "kms_master_key" {       config_path = "../../../../_global/kms-master-key"     }     inputs = {       iam_policy = {         AccessKMSKey = {           effect    = "Allow"           actions   = ["kms:Decrypt"]           resources = [dependency.kms_master_key.outputs.key_arn]         }       }     }`

=== Removed Inputs

Remove the following inputs as they are not present in the Service Catalog version of the module:

* `image`
* `image_version`
* `db_remote_state_path`
* `db_url_env_var_name`
* `memcached_remote_state_path`
* `memcached_url_env_var_name`
* `redis_remote_state_path`
* `redis_url_env_var_name`
* `vpc_env_var_name`
* `extra_env_vars`

=== State Migration Script

Run the provided migration script to migrate the state in a backward compatible way:

[source,python]
----
terragrunt state mv \
  module.alb_access_logs_bucket.aws_s3_bucket.access_logs[0] \
  module.alb_access_logs_bucket.module.access_logs.aws_s3_bucket.bucket[0]
----

=== Breaking Changes

* This change is fully backward compatible.
* 3 resources will be created: `null_resource.sleep_for_resource_culling`, `aws_s3_bucket_policy.bucket_policy[0]`, and
`aws_s3_bucket_public_access_block.public_access[0]`. You can ignore this.
* When applying the change, the bucket policy will be removed from the bucket resource and will be replaced with a new
`aws_s3_bucket_policy` resource. This policy allows ALB to deliver access logs to the S3 bucket. The existing bucket is
NOT destroyed. When you run the migration script, the existing bucket is moved to the new address. However, the bucket
policy is recreated, which may cause a brief outage (<1 minute) in access log delivery while the policy change occurs.
* This is a zero-downtime migration, meaning that you should have no loss of service during the `apply` step of this
migration.
